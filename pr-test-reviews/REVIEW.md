# Review Guide

### **[Reviewer Read:] Test Review Process**
**Your task is to review if a generated test is worth adding to a PR. The test is generated by a LLM, and the PR is from an open source project. The test improves the PR's patch coverage.**

Specifically, you will need to first review the PR and understand the why some patch coverage is missing.

Navigate to the designated directory (e.g. `reviews/001/pandas`). For each PR, you will find the following files:
- `$pr_number.md`: a markdown containing the PR's link, summary, patch coverage visualization, and the complete diff
- `test_*`: A directory containing a selected test that adds some coverage
    - `test_*.patch`: the test diff to be submitted
    - `test_*.py`: the test file after the patch is applied
    - **`test_summary.md`: the self-contained markdown regarding the test, most of the time, you only need to read this**

### **[Reviewer Read: ] Scoring**
You will score the test on 5-point Likert scale (strongly disapprove, disapprove, don't know, approve, strongly approve) for each of the following criteria:**

- The extra test coverage is **worthwhile** to add.
    - +Example: a test for a corner case, a developmental feature, which are error-prone. This means the additional tests have a higher chance of catching some regression bugs eventually.
    - -Example: a test that adds coverage to a 1-line getter which is unlikely to be buggy
- The test is **well integrated** into the existing test suite. 
    - +Example: the test uses existing fixtures to set up the environment, ensuring consistency and reducing redundancy.
    - -Example: the test hardcoded parameters, while other test functions in the context are property-based tests that are parameterized.
- The test is **related to** the PR.
    - +Example: the PR adds corner case handling in a scipy optimization function. But forgets to test the corner case. The new test is for the corner case. 
    - -Example: the uncovered lines are formatting changes by the PR. In this case we may need to trace back to the PR that modified or introduced the uncovered line in a meaningful way.

### **[Reviewer Read: ] Scoring Template**
Use the following yaml template to record your scores. Create a new file named `scores_{nickname}.yaml` in the directory of the test you are reviewing. To avoid bias, you should not read other reviewers' scores before you submit your own.
```yaml
reviewer: <your_nickname>
scores:
# 1 for strongly disapprove, 5 for strongly approve
  - criterion: "worthwhile"
    score: <1-5>
    comment: "<your_comment>"
  - criterion: "well integrated"
    score: <1-5>
    comment: "<your_comment>"
  - criterion: "related to PR"
    score: <1-5>
    comment: "<your_comment>"
```
