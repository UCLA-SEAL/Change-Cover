## [PR 22969](https://github.com/scipy/scipy/pull/22969)

## PR Summary

This pull request (PR #22969) focuses on maintaining the `stats.make_distribution` function by fixing several outstanding issues specific to discrete distributions. It addresses problems with `nchypergeom_fisher`, `zipfian`, and ensures tests run correctly for `betanbinom`, `zipf`, and `logser`. Additionally, it includes fixes for noncentral hypergeometric failures. These enhancements are part of the upcoming 1.16.0 milestone and contribute to the overall functionality and reliability of the SciPy library. This PR builds upon prior work that introduced new discrete distribution infrastructure (see PR #22312).

## Uncovered Lines

```python
--------------------------------------------------------------------------------
# scipy/stats/_discrete_distns.py
--------------------------------------------------------------------------------
class binom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, n, p, size=None, random_state=None):
...
    def _argcheck(self, n, p):
...
    def _get_support(self, n, p):
...
    def _logpmf(self, x, n, p):
...
    def _pmf(self, x, n, p):
        # binom.pmf(k) = choose(n, k) * p**k * (1-p)**(n-k)
...
    def _cdf(self, x, n, p):
...
    def _sf(self, x, n, p):
...
    def _isf(self, x, n, p):
...
    def _ppf(self, q, n, p):
...
    def _stats(self, n, p, moments='mv'):
...
    def _entropy(self, n, p):
...
class bernoulli_gen(binom_gen):
...
    def _shape_info(self):
...
    def _rvs(self, p, size=None, random_state=None):
...
    def _argcheck(self, p):
...
    def _get_support(self, p):
        # Overrides binom_gen._get_support!x
...
    def _logpmf(self, x, p):
...
    def _pmf(self, x, p):
        # bernoulli.pmf(k) = 1-p  if k = 0
        #                  = p    if k = 1
...
    def _cdf(self, x, p):
...
    def _sf(self, x, p):
...
    def _isf(self, x, p):
...
    def _ppf(self, q, p):
...
    def _stats(self, p):
...
    def _entropy(self, p):
...
class betabinom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, n, a, b, size=None, random_state=None):
...
    def _get_support(self, n, a, b):
...
    def _argcheck(self, n, a, b):
...
    def _logpmf(self, x, n, a, b):
...
    def _pmf(self, x, n, a, b):
...
    def _stats(self, n, a, b, moments='mv'):
...
class nbinom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, n, p, size=None, random_state=None):
...
    def _argcheck(self, n, p):
...
    def _pmf(self, x, n, p):
        # nbinom.pmf(k) = choose(k+n-1, n-1) * p**n * (1-p)**k
...
    def _logpmf(self, x, n, p):
...
    def _cdf(self, x, n, p):
...
    def _logcdf(self, x, n, p):
...
        def f1(k, n, p):
...
    def _sf(self, x, n, p):
...
    def _isf(self, x, n, p):
...
    def _ppf(self, q, n, p):
...
    def _stats(self, n, p):
...
class betanbinom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, n, a, b, size=None, random_state=None):
...
    def _argcheck(self, n, a, b):
...
    def _logpmf(self, x, n, a, b):
...
    def _pmf(self, x, n, a, b):
...
    def _stats(self, n, a, b, moments='mv'):
        # reference: Wolfram Alpha input
        # BetaNegativeBinomialDistribution[a, b, n]
        def mean(n, a, b):
...
        def var(n, a, b):
...
        def skew(n, a, b):
...
        def kurtosis(n, a, b):
...
class geom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, p, size=None, random_state=None):
...
    def _argcheck(self, p):
...
    def _pmf(self, k, p):
...
    def _logpmf(self, k, p):
...
    def _cdf(self, x, p):
...
    def _sf(self, x, p):
...
    def _logsf(self, x, p):
...
    def _ppf(self, q, p):
...
    def _stats(self, p):
...
    def _entropy(self, p):
...
class hypergeom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, M, n, N, size=None, random_state=None):
...
    def _get_support(self, M, n, N):
...
    def _argcheck(self, M, n, N):
...
    def _logpmf(self, k, M, n, N):
...
    def _pmf(self, k, M, n, N):
...
    def _cdf(self, k, M, n, N):
...
    def _stats(self, M, n, N):
...
    def _entropy(self, M, n, N):
...
    def _sf(self, k, M, n, N):
...
    def _logsf(self, k, M, n, N):
...
    def _logcdf(self, k, M, n, N):
...
class nhypergeom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _get_support(self, M, n, r):
...
    def _argcheck(self, M, n, r):
...
    def _rvs(self, M, n, r, size=None, random_state=None):

        @_vectorize_rvs_over_shapes
        def _rvs1(M, n, r, size, random_state):
            # invert cdf by calculating all values in support, scalar M, n, r
...
    def _logpmf(self, k, M, n, r):
...
    def _pmf(self, k, M, n, r):
        # same as the following but numerically more precise
        # return comb(k+r-1, k) * comb(M-r-k, n-k) / comb(M, n)
...
    def _stats(self, M, n, r):
        # Promote the datatype to at least float
        # mu = rn / (M-n+1)
...
class logser_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, p, size=None, random_state=None):
        # looks wrong for p>0.5, too few k=1
        # trying to use generic is worse, no k=1 at all
...
    def _argcheck(self, p):
...
    def _pmf(self, k, p):
        # logser.pmf(k) = - p**k / (k*log(1-p))
...
    def _stats(self, p):
...
class poisson_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _argcheck(self, mu):
...
    def _rvs(self, mu, size=None, random_state=None):
...
    def _logpmf(self, k, mu):
...
    def _pmf(self, k, mu):
        # poisson.pmf(k) = exp(-mu) * mu**k / k!
...
    def _cdf(self, x, mu):
...
    def _sf(self, x, mu):
...
    def _ppf(self, q, mu):
...
    def _stats(self, mu):
...
class planck_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _argcheck(self, lambda_):
...
    def _pmf(self, k, lambda_):
...
    def _cdf(self, x, lambda_):
...
    def _sf(self, x, lambda_):
...
    def _logsf(self, x, lambda_):
...
    def _ppf(self, q, lambda_):
...
    def _rvs(self, lambda_, size=None, random_state=None):
        # use relation to geometric distribution for sampling
...
    def _stats(self, lambda_):
...
    def _entropy(self, lambda_):
...
class boltzmann_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _argcheck(self, lambda_, N):
...
    def _get_support(self, lambda_, N):
...
    def _pmf(self, k, lambda_, N):
        # boltzmann.pmf(k) =
        #               (1-exp(-lambda_)*exp(-lambda_*k)/(1-exp(-lambda_*N))
...
    def _cdf(self, x, lambda_, N):
...
    def _ppf(self, q, lambda_, N):
...
    def _stats(self, lambda_, N):
...
class randint_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _argcheck(self, low, high):
...
    def _get_support(self, low, high):
...
    def _pmf(self, k, low, high):
        # randint.pmf(k) = 1./(high - low)
...
    def _cdf(self, x, low, high):
...
    def _ppf(self, q, low, high):
...
    def _stats(self, low, high):
...
    def _rvs(self, low, high, size=None, random_state=None):
...
    def _entropy(self, low, high):
...
class zipf_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, a, size=None, random_state=None):
...
    def _argcheck(self, a):
...
    def _pmf(self, k, a):
...
    def _munp(self, n, a):
...
def _gen_harmonic_gt1(n, a):
...
def _gen_harmonic_leq1(n, a):
...
def _gen_harmonic(n, a):
...
class zipfian_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _argcheck(self, a, n):
        # we need np.asarray here because moment (maybe others) don't convert
...
    def _get_support(self, a, n):
...
    def _pmf(self, k, a, n):
...
    def _cdf(self, k, a, n):
...
    def _sf(self, k, a, n):
...
    def _stats(self, a, n):
        # see # see http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Zipf.pdf
...
class dlaplace_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _pmf(self, k, a):
        # dlaplace.pmf(k) = tanh(a/2) * exp(-a*abs(k))
...
    def _cdf(self, x, a):
...
        def f1(k, a):
...
        def f2(k, a):
...
    def _ppf(self, q, a):
...
    def _stats(self, a):
...
    def _entropy(self, a):
...
    def _rvs(self, a, size=None, random_state=None):
        # The discrete Laplace is equivalent to the two-sided geometric
        # distribution with PMF:
        #   f(k) = (1 - alpha)/(1 + alpha) * alpha^abs(k)
        #   Reference:
        #     https://www.sciencedirect.com/science/
        #     article/abs/pii/S0378375804003519
        # Furthermore, the two-sided geometric distribution is
        # equivalent to the difference between two iid geometric
        # distributions.
        #   Reference (page 179):
        #     https://pdfs.semanticscholar.org/61b3/
        #     b99f466815808fd0d03f5d2791eea8b541a1.pdf
        # Thus, we can leverage the following:
        #   1) alpha = e^-a
        #   2) probability_of_success = 1 - alpha (Bernoulli trial)
...
class poisson_binom_gen(rv_discrete):
...
    def _shape_info(self):
        # message = 'Fitting is not implemented for this distribution."
        # raise NotImplementedError(message)
...
    def _argcheck(self, *args):
...
    def _rvs(self, *args, size=None, random_state=None):
        # convenient to work along the last axis here to avoid interference with `size`
...
    def _get_support(self, *args):
...
    def _pmf(self, k, *args):
...
    def _cdf(self, k, *args):
...
    def _stats(self, *args, **kwds):
...
    def __call__(self, *args, **kwds):
...
def _parse_args_rvs(self, p, loc=0, size=None):
...
def _parse_args_stats(self, p, loc=0, moments='mv'):
...
def _parse_args(self, p, loc=0):
...
class poisson_binomial_frozen(rv_discrete_frozen):
    # copied from rv_frozen; we just need to bind the `_parse_args` methods
    def __init__(self, dist, *args, **kwds):                        # verbatim
...
    def expect(self, func=None, lb=None, ub=None, conditional=False, **kwds):
...
class skellam_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, mu1, mu2, size=None, random_state=None):
...
    def _pmf(self, x, mu1, mu2):
...
    def _cdf(self, x, mu1, mu2):
...
    def _stats(self, mu1, mu2):
...
class yulesimon_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _rvs(self, alpha, size=None, random_state=None):
...
    def _pmf(self, x, alpha):
...
    def _argcheck(self, alpha):
...
    def _logpmf(self, x, alpha):
...
    def _cdf(self, x, alpha):
...
    def _sf(self, x, alpha):
...
    def _logsf(self, x, alpha):
...
    def _stats(self, alpha):
...
class _nchypergeom_gen(rv_discrete):
...
    def _shape_info(self):
...
    def _get_support(self, M, n, N, odds):
...
    def _argcheck(self, M, n, N, odds):
...
        cond4 = odds > 0
        cond5 = N <= M
        cond6 = n <= M
        return cond1 & cond2 & cond3 & cond4 & cond5 & cond6

    def _rvs(self, M, n, N, odds, size=None, random_state=None):

        @_vectorize_rvs_over_shapes
        def _rvs1(M, n, N, odds, size, random_state):
            if np.isnan(M) | np.isnan(n) | np.isnan(N):
                return np.full(size, np.nan) #❗UNCOVERED: NEED TEST
            length = np.prod(size)
            urn = _PyStochasticLib3()
            rv_gen = getattr(urn, self.rvs_name)
            rvs = rv_gen(N, n, M, odds, length, random_state)
            rvs = rvs.reshape(size)
            return rvs

        return _rvs1(M, n, N, odds, size=size, random_state=random_state)

    def _pmf(self, x, M, n, N, odds):

...
        def _pmf1(x, M, n, N, odds):
...
            urn = self.dist(N, n, M, odds, 1e-12)
            return urn.probability(x)

        return _pmf1(x, M, n, N, odds)

    def _stats(self, M, n, N, odds, moments='mv'):

        @np.vectorize
        def _moments1(M, n, N, odds):
            if np.isnan(M) | np.isnan(n) | np.isnan(N):
                return np.nan, np.nan #❗UNCOVERED: NEED TEST
            urn = self.dist(N, n, M, odds, 1e-12)
            return urn.moments()

        m, v = (_moments1(M, n, N, odds) if ("m" in moments or "v" in moments)
                else (None, None))
        s, k = None, None
        return m, v, s, k


class nchypergeom_fisher_gen(_nchypergeom_gen):
...
class nchypergeom_wallenius_gen(_nchypergeom_gen):

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# scipy/stats/_distribution_infrastructure.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# scipy/stats/tests/test_continuous.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
```

## PR Diff

```diff
diff --git a/scipy/stats/_discrete_distns.py b/scipy/stats/_discrete_distns.py
index 1e3340506e37..ac12ef17aa3d 100644
--- a/scipy/stats/_discrete_distns.py
+++ b/scipy/stats/_discrete_distns.py
@@ -1371,12 +1371,13 @@ def _gen_harmonic_leq1(n, a):
     """Generalized harmonic number, a <= 1"""
     if not np.size(n):
         return n
-    n_max = np.max(n)  # loop starts at maximum of all n
+    n_max = np.nanmax(n)  # loop starts at maximum of all n
     out = np.zeros_like(a, dtype=float)
     # add terms of harmonic series; starting from smallest to avoid roundoff
     for i in np.arange(n_max, 0, -1, dtype=float):
         mask = i <= n  # don't add terms after nth
         out[mask] += 1/i**a[mask]
+    out[np.isnan(n)] = np.nan
     return out
 
 
@@ -1871,9 +1872,9 @@ def _get_support(self, M, n, N, odds):
     def _argcheck(self, M, n, N, odds):
         M, n = np.asarray(M), np.asarray(n),
         N, odds = np.asarray(N), np.asarray(odds)
-        cond1 = (M.astype(int) == M) & (M >= 0)
-        cond2 = (n.astype(int) == n) & (n >= 0)
-        cond3 = (N.astype(int) == N) & (N >= 0)
+        cond1 = (~np.isnan(M)) & (M.astype(int) == M) & (M >= 0)
+        cond2 = (~np.isnan(n)) & (n.astype(int) == n) & (n >= 0)
+        cond3 = (~np.isnan(N)) & (N.astype(int) == N) & (N >= 0)
         cond4 = odds > 0
         cond5 = N <= M
         cond6 = n <= M
@@ -1883,6 +1884,8 @@ def _rvs(self, M, n, N, odds, size=None, random_state=None):
 
         @_vectorize_rvs_over_shapes
         def _rvs1(M, n, N, odds, size, random_state):
+            if np.isnan(M) | np.isnan(n) | np.isnan(N):
+                return np.full(size, np.nan)
             length = np.prod(size)
             urn = _PyStochasticLib3()
             rv_gen = getattr(urn, self.rvs_name)
@@ -1900,15 +1903,19 @@ def _pmf(self, x, M, n, N, odds):
 
         @np.vectorize
         def _pmf1(x, M, n, N, odds):
+            if np.isnan(x) | np.isnan(M) | np.isnan(n) | np.isnan(N):
+                return np.nan
             urn = self.dist(N, n, M, odds, 1e-12)
             return urn.probability(x)
 
         return _pmf1(x, M, n, N, odds)
 
-    def _stats(self, M, n, N, odds, moments):
+    def _stats(self, M, n, N, odds, moments='mv'):
 
         @np.vectorize
         def _moments1(M, n, N, odds):
+            if np.isnan(M) | np.isnan(n) | np.isnan(N):
+                return np.nan, np.nan
             urn = self.dist(N, n, M, odds, 1e-12)
             return urn.moments()
 
diff --git a/scipy/stats/_distribution_infrastructure.py b/scipy/stats/_distribution_infrastructure.py
index 13b8380c5a95..94b2243d177b 100644
--- a/scipy/stats/_distribution_infrastructure.py
+++ b/scipy/stats/_distribution_infrastructure.py
@@ -3856,8 +3856,7 @@ def make_distribution(dist):
 
         `make_distribution` does not work perfectly with all instances of
         `rv_continuous`. Known failures include `levy_stable`, `vonmises`,
-        `hypergeom`, `nchypergeom_fisher`, `nchypergeom_wallenius`,
-        `poisson_binom`; and some methods of some distributions
+        `hypergeom`, `poisson_binom`, and 'skellam'. Some methods of some distributions
         will not support array shape parameters.
 
     Parameters
@@ -4066,8 +4065,7 @@ class or its methods for more information.
 
     """
     if dist in {stats.levy_stable, stats.vonmises, stats.hypergeom,
-                stats.nchypergeom_fisher, stats.nchypergeom_wallenius,
-                stats.poisson_binom}:
+                stats.poisson_binom, stats.skellam}:
         raise NotImplementedError(f"`{dist.name}` is not supported.")
 
     if isinstance(dist, stats.rv_continuous | stats.rv_discrete):
diff --git a/scipy/stats/tests/test_continuous.py b/scipy/stats/tests/test_continuous.py
index 5132d54eebf8..2be327145c2e 100644
--- a/scipy/stats/tests/test_continuous.py
+++ b/scipy/stats/tests/test_continuous.py
@@ -1113,7 +1113,7 @@ def test_rv_generic(self, i, distdata):
                 'johnsonsb', 'kappa4', 'ksone', 'kstwo', 'kstwobign', 'norminvgauss',
                 'powerlognorm', 'powernorm', 'recipinvgauss', 'studentized_range',
                 'vonmises_line', # continuous
-                'betanbinom', 'zipf', 'logser', 'skellam'}  # discrete
+                'skellam'}  # discrete
         if not int(os.environ.get('SCIPY_XSLOW', '0')) and distname in slow:
             pytest.skip('Skipping as XSLOW')
 
@@ -1122,25 +1122,24 @@ def test_rv_generic(self, i, distdata):
             'vonmises',               # circular distribution; shouldn't work
             'poisson_binom',          # vector shape parameter
             'hypergeom',              # distribution functions need interpolation
-            'nchypergeom_fisher',     # distribution functions don't accept NaN
-            'nchypergeom_wallenius',  # distribution functions don't accept NaN
-            'skellam',                # during `entropy`, Fatal Python error: Aborted!
-            'zipfian',                # during init, value error due to unexpected nans
+            'skellam',                # gh-22956 (_ncx2_pdf crashes with extreme input)
         }:
             return
 
         # skip single test, mostly due to slight disagreement
         custom_tolerances = {'ksone': 1e-5, 'kstwo': 1e-5}  # discontinuous PDF
         skip_entropy = {'kstwobign', 'pearson3'}  # tolerance issue
-        skip_skewness = {'exponpow', 'ksone'}  # tolerance issue
-        skip_kurtosis = {'chi', 'exponpow', 'invgamma',  # tolerance issue
-                         'johnsonsb', 'ksone', 'kstwo'}  # tolerance issue
+        skip_skewness = {'exponpow', 'ksone', 'nchypergeom_wallenius'}  # tolerance
+        skip_kurtosis = {'chi', 'exponpow', 'invgamma',  # tolerance
+                         'johnsonsb', 'ksone', 'kstwo',  # tolerance
+                         'nchypergeom_wallenius'}  # tolerance
         skip_logccdf = {'arcsine', 'skewcauchy', 'trapezoid', 'triang'}  # tolerance
         skip_raw = {2: {'alpha', 'foldcauchy', 'halfcauchy', 'levy', 'levy_l'},
                     3: {'pareto'},  # stats.pareto is just wrong
                     4: {'invgamma'}}  # tolerance issue
-        skip_standardized = {'exponpow', 'ksone'}  # tolerances
-        skip_median = {'nhypergeom', 'yulesimon'}  # nan mismatch
+        skip_standardized = {'exponpow', 'ksone', 'nchypergeom_wallenius'}  # tolerances
+        skip_median = {'nhypergeom', 'yulesimon',  # nan mismatch
+                       'betanbinom', 'zipf', 'logser'}  # median 0th element
 
         dist = getattr(stats, distname)
         params = dict(zip(dist.shapes.split(', '), distdata[1])) if dist.shapes else {}
@@ -1195,10 +1194,14 @@ def test_rv_generic(self, i, distdata):
                 if distname not in skip_standardized:
                     assert_allclose(X.moment(order, kind='standardized'),
                                     Y.stats('mvsk'[order-1]), rtol=rtol, atol=atol)
-            seed = 845298245687345
-            assert_allclose(X.sample(shape=10, rng=seed),
-                            Y.rvs(size=10, random_state=np.random.default_rng(seed)),
-                            rtol=rtol)
+            if isinstance(dist, stats.rv_continuous):
+                # For discrete distributions, these won't agree at the far left end
+                # of the support, and the new infrastructure is slow there (for now).
+                seed = 845298245687345
+                assert_allclose(X.sample(shape=10, rng=seed),
+                                Y.rvs(size=10,
+                                      random_state=np.random.default_rng(seed)),
+                                rtol=rtol)
 
     def test_custom(self):
         rng = np.random.default_rng(7548723590230982)

```
