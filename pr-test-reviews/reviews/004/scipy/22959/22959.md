## [PR 22959](https://github.com/scipy/scipy/pull/22959)

## PR Summary

Summary: This pull request enhances the `scipy.cluster` module by adding more lazy functions to improve support for JAX's JIT compilation and avoid unnecessary materialization of Dask graphs. Key updates include modifications to functions such as `cophenet`, `inconsistent`, and `is_isomorphic`, which lead to performance improvements while ensuring existing tests pass without regressions. The PR also includes code cleanups for better readability, particularly the vectorization of the `is_isomorphic` function.

## Uncovered Lines

```python
--------------------------------------------------------------------------------
# scipy/cluster/hierarchy.py
--------------------------------------------------------------------------------
class ClusterWarning(UserWarning):
...
def _warning(s):
...
def int_floor(arr, xp):
    # array_api_strict is strict about not allowing `int()` on a float array.
    # That's typically not needed, here it is - so explicitly convert
...
def single(y):
...
def complete(y):
...
def average(y):
...
def weighted(y):
...
def centroid(y):
...
def median(y):
...
def ward(y):
...
def linkage(y, method='single', metric='euclidean', optimal_ordering=False):
...
    def cy_linkage(y, validate):
...
class ClusterNode:
...
    def __init__(self, id, left=None, right=None, dist=0.0, count=1):
...
    def __lt__(self, node):
...
    def __gt__(self, node):
...
    def __eq__(self, node):
...
    def get_id(self):
...
    def get_count(self):
...
    def get_left(self):
...
    def get_right(self):
...
    def is_leaf(self):
...
    def pre_order(self, func=(lambda x: x.id)):
...
def _order_cluster_tree(Z):
...
def cut_tree(Z, n_clusters=None, height=None):
...
def to_tree(Z, rd=False):
...
def optimal_leaf_ordering(Z, y, metric='euclidean'):
...
    def cy_optimal_leaf_ordering(Z, y, validate):
...
def cophenet(Z, Y=None):
...
    def cy_cophenet(Z, validate):
...
def inconsistent(Z, d=2):
...
    def cy_inconsistent(Z, d, validate):
...
def from_mlab_linkage(Z):
...
    if not lazy and xp.min(Z[:, :2]) != 1.0 and xp.max(Z[:, :2]) != 2 * n:
        raise ValueError('The format of the indices is not 1..N')

    res = xp.empty((Z.shape[0], Z.shape[1] + 1), dtype=Z.dtype)
    res = xpx.at(res)[:, :2].set(Z[:, :2] - 1.0)
    res = xpx.at(res)[:, 2:-1].set(Z[:, 2:])

    def cy_from_mlab_linkage(Zpart, validate):
        n = Zpart.shape[0]
        if validate and np.min(Zpart[:, :2]) != 0.0 and np.max(Zpart[:, :2]) != 2 * n:
            raise ValueError('The format of the indices is not 1..N') #❗UNCOVERED: NEED TEST

        if not Zpart.flags.writeable:
            Zpart = Zpart.copy()  # xp=jax.numpy #❗UNCOVERED: NEED TEST

        CS = np.zeros((n,))
        _hierarchy.calculate_cluster_sizes(Zpart, CS, n + 1)
        return CS

    CS = xpx.lazy_apply(cy_from_mlab_linkage, res[:, :-1], validate=lazy,
                        shape=(res.shape[0],), dtype=xp.float64,
                        as_numpy=True, xp=xp)

    return xpx.at(res)[:, -1].set(CS)
...
def to_mlab_linkage(Z):
...
def is_monotonic(Z):
...
def is_valid_im(R, warning=False, throw=False, name=None):
...
def _is_valid_im(R, warning=False, throw=False, name=None, materialize=False, *, xp):
...
def is_valid_linkage(Z, warning=False, throw=False, name=None):
...
def _is_valid_linkage(Z, warning=False, throw=False, name=None,
                      materialize=False, *, xp):
...
def _lazy_valid_checks(*args, throw=False, warning=False, materialize=False, xp):
...
def num_obs_linkage(Z):
...
def correspond(Z, Y):
...
def fcluster(Z, t, criterion='inconsistent', depth=2, R=None, monocrit=None):
...
def fclusterdata(X, t, criterion='inconsistent',
                 metric='euclidean', depth=2, method='single', R=None):
...
    X = _asarray(X, order='C', dtype=xp.float64, xp=xp)

    if X.ndim != 2:
        raise TypeError('The observation matrix X must be an n by m array.')

    Y = distance.pdist(X, metric=metric)
    Z = linkage(Y, method=method)
    if R is None:
        R = inconsistent(Z, d=depth)
    else:
        R = _asarray(R, order='C', xp=xp) #❗UNCOVERED: NEED TEST
    T = fcluster(Z, criterion=criterion, depth=depth, R=R, t=t)
    return T


def leaves_list(Z):
    """
    Return a list of leaf node ids.

    The return corresponds to the observation vector index as it appears
    in the tree from left to right. Z is a linkage matrix.
...
    def cy_leaves_list(Z, validate):
...
def _remove_dups(L):
...
def _get_tick_text_size(p):
...
def _get_tick_rotation(p):
...
def _plot_dendrogram(icoords, dcoords, ivl, p, n, mh, orientation,
                     no_labels, color_list, leaf_font_size=None,
                     leaf_rotation=None, contraction_marks=None,
                     ax=None, above_threshold_color='C0'):
    # Import matplotlib here so that it's not imported unless dendrograms
    # are plotted. Raise an informative error if importing fails.
...
def set_link_color_palette(palette):
...
def dendrogram(Z, p=30, truncate_mode=None, color_threshold=None,
               get_leaves=True, orientation='top', labels=None,
               count_sort=False, distance_sort=False, show_leaf_counts=True,
               no_plot=False, no_labels=False, leaf_font_size=None,
               leaf_rotation=None, leaf_label_func=None,
               show_contracted=False, link_color_func=None, ax=None,
               above_threshold_color='C0'):
...
def _get_leaves_color_list(R):
...
def _append_singleton_leaf_node(Z, p, n, level, lvs, ivl, leaf_label_func,
                                i, labels):
    # If the leaf id structure is not None and is a list then the caller
    # to dendrogram has indicated that cluster id's corresponding to the
    # leaf nodes should be recorded.

...
def _append_nonsingleton_leaf_node(Z, p, n, level, lvs, ivl, leaf_label_func,
                                   i, labels, show_leaf_counts):
    # If the leaf id structure is not None and is a list then the caller
    # to dendrogram has indicated that cluster id's corresponding to the
    # leaf nodes should be recorded.

...
def _append_contraction_marks(Z, iv, i, n, contraction_marks, xp):
...
def _append_contraction_marks_sub(Z, iv, i, n, contraction_marks, xp):
...
def _dendrogram_calculate_info(Z, p, truncate_mode,
                               color_threshold=np.inf, get_leaves=True,
                               orientation='top', labels=None,
                               count_sort=False, distance_sort=False,
                               show_leaf_counts=False, i=-1, iv=0.0,
                               ivl=None, n=0, icoord_list=None, dcoord_list=None,
                               lvs=None, mhr=False,
                               current_color=None, color_list=None,
                               currently_below_threshold=None,
                               leaf_label_func=None, level=0,
                               contraction_marks=None,
                               link_color_func=None,
                               above_threshold_color='C0'):
...
def is_isomorphic(T1, T2):
...
    def py_is_isomorphic(T1, T2):
...
def maxdists(Z):
...
    def cy_maxdists(Z, validate):
...
def maxinconsts(Z, R):
...
    def cy_maxinconsts(Z, R, validate):
...
def maxRstat(Z, R, i):
...
    def cy_maxRstat(Z, R, i, validate):
...
def leaders(Z, T):
...
    def cy_leaders(Z, T, validate):

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# scipy/cluster/tests/test_hierarchy.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
```

## PR Diff

```diff
diff --git a/scipy/cluster/hierarchy.py b/scipy/cluster/hierarchy.py
index 56620ad9a8d9..d8cac08aee0a 100644
--- a/scipy/cluster/hierarchy.py
+++ b/scipy/cluster/hierarchy.py
@@ -134,7 +134,7 @@
 import numpy as np
 from . import _hierarchy, _optimal_leaf_ordering
 import scipy.spatial.distance as distance
-from scipy._lib._array_api import (_asarray, array_namespace, is_dask, is_jax,
+from scipy._lib._array_api import (_asarray, array_namespace, is_dask,
                                    is_lazy_array, xp_copy)
 from scipy._lib._disjoint_set import DisjointSet
 import scipy._lib.array_api_extra as xpx
@@ -165,7 +165,7 @@ def _warning(s):
 def int_floor(arr, xp):
     # array_api_strict is strict about not allowing `int()` on a float array.
     # That's typically not needed, here it is - so explicitly convert
-    return int(xp.astype(xp.asarray(arr), xp.int64))
+    return int(xp.asarray(arr, dtype=xp.int64))
 
 
 def single(y):
@@ -1049,7 +1049,8 @@ def cy_linkage(y, validate):
             return _hierarchy.fast_linkage(y, n, method_code)
 
     result = xpx.lazy_apply(cy_linkage, y, validate=lazy,
-                            shape=(n - 1, 4), dtype=xp.float64, as_numpy=True)
+                            shape=(n - 1, 4), dtype=xp.float64,
+                            as_numpy=True, xp=xp)
 
     if optimal_ordering:
         return optimal_leaf_ordering(result, y)
@@ -1438,8 +1439,8 @@ def to_tree(Z, rd=False):
 
     """
     xp = array_namespace(Z)
-    Z = _asarray(Z, order='c', xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
+    Z = _asarray(Z, order='C', xp=xp)
+    _is_valid_linkage(Z, throw=True, name='Z', materialize=True, xp=xp)
 
     # Number of original objects is equal to the number of rows plus 1.
     n = Z.shape[0] + 1
@@ -1523,7 +1524,7 @@ def optimal_leaf_ordering(Z, y, metric='euclidean'):
     Z = _asarray(Z, order='C', xp=xp)
     y = _asarray(y, order='C', dtype=xp.float64, xp=xp)
     lazy = is_lazy_array(Z)
-    _is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
     if y.ndim == 1:
         distance.is_valid_y(y, throw=True, name='y')
@@ -1544,16 +1545,16 @@ def optimal_leaf_ordering(Z, y, metric='euclidean'):
 
     # The function name is prominently visible on the user-facing Dask dashboard;
     # make sure it is meaningful.
-    def optimal_leaf_ordering_(Z, y, validate):
+    def cy_optimal_leaf_ordering(Z, y, validate):
         if validate:
-            is_valid_linkage(Z, throw=True, name='Z')
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
             if not np.all(np.isfinite(y)):
                 raise ValueError("The condensed distance matrix must contain only "
                                  "finite values.")
         return _optimal_leaf_ordering.optimal_leaf_ordering(Z, y)
 
-    return xpx.lazy_apply(optimal_leaf_ordering_, Z, y, validate=lazy,
-                          shape=Z.shape, dtype=Z.dtype, as_numpy=True)
+    return xpx.lazy_apply(cy_optimal_leaf_ordering, Z, y, validate=lazy,
+                          shape=Z.shape, dtype=Z.dtype, as_numpy=True, xp=xp)
 
 
 def cophenet(Z, Y=None):
@@ -1666,13 +1667,21 @@ def cophenet(Z, Y=None):
     xp = array_namespace(Z, Y)
     # Ensure float64 C-contiguous array. Cython code doesn't deal with striding.
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
-    n = Z.shape[0] + 1
-    zz = np.zeros((n * (n-1)) // 2, dtype=np.float64)
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
-    Z = np.asarray(Z)
-    _hierarchy.cophenetic_distances(Z, zz, int(n))
-    zz = xp.asarray(zz)
+    def cy_cophenet(Z, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+        n = Z.shape[0] + 1
+        zz = np.zeros((n * (n-1)) // 2, dtype=np.float64)
+        _hierarchy.cophenetic_distances(Z, zz, n)
+        return zz
+    
+    n = Z.shape[0] + 1
+    zz = xpx.lazy_apply(cy_cophenet, Z, validate=is_lazy_array(Z),
+                        shape=((n * (n-1)) // 2, ), dtype=xp.float64,
+                        as_numpy=True, xp=xp)
+                        
     if Y is None:
         return zz
 
@@ -1747,19 +1756,23 @@ def inconsistent(Z, d=2):
     """
     xp = array_namespace(Z)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
-    if (not d == np.floor(d)) or d < 0:
+    if d != np.floor(d) or d < 0:
         raise ValueError('The second argument d must be a nonnegative '
                          'integer value.')
 
-    n = Z.shape[0] + 1
-    R = np.zeros((n - 1, 4), dtype=np.float64)
+    def cy_inconsistent(Z, d, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+        R = np.zeros((Z.shape[0], 4), dtype=np.float64)
+        n = Z.shape[0] + 1
+        _hierarchy.inconsistent(Z, R, n, d)
+        return R
 
-    Z = np.asarray(Z)
-    _hierarchy.inconsistent(Z, R, int(n), int(d))
-    R = xp.asarray(R)
-    return R
+    return xpx.lazy_apply(cy_inconsistent, Z, d=int(d), validate=is_lazy_array(Z),
+                          shape=(Z.shape[0], 4), dtype=xp.float64,
+                          as_numpy=True, xp=xp)
 
 
 def from_mlab_linkage(Z):
@@ -1834,32 +1847,45 @@ def from_mlab_linkage(Z):
     """
     xp = array_namespace(Z)
     Z = _asarray(Z, dtype=xp.float64, order='C', xp=xp)
-    Zs = Z.shape
 
     # If it's empty, return it.
-    if len(Zs) == 0 or (len(Zs) == 1 and Zs[0] == 0):
+    if Z.shape in ((), (0, )):
         return xp_copy(Z, xp=xp)
 
-    if len(Zs) != 2:
+    if Z.ndim != 2:
         raise ValueError("The linkage array must be rectangular.")
 
     # If it contains no rows, return it.
-    if Zs[0] == 0:
+    n = Z.shape[0]
+    if n == 0:
         return xp_copy(Z, xp=xp)
 
-    if xp.min(Z[:, 0:2]) != 1.0 and xp.max(Z[:, 0:2]) != 2 * Zs[0]:
+    lazy = is_lazy_array(Z)
+
+    if not lazy and xp.min(Z[:, :2]) != 1.0 and xp.max(Z[:, :2]) != 2 * n:
         raise ValueError('The format of the indices is not 1..N')
 
-    Zpart = xp.concat((Z[:, 0:2] - 1.0, Z[:, 2:]), axis=1)
-    CS = np.zeros((Zs[0],), dtype=np.float64)
-    if is_jax(xp):
-        # calculate_cluster_sizes doesn't accept read-only arrays
-        Zpart = np.array(Zpart, copy=True)
-    else:
-        Zpart = np.asarray(Zpart)
-    _hierarchy.calculate_cluster_sizes(Zpart, CS, int(Zs[0]) + 1)
-    res = np.hstack([Zpart, CS.reshape(Zs[0], 1)])
-    return xp.asarray(res)
+    res = xp.empty((Z.shape[0], Z.shape[1] + 1), dtype=Z.dtype)
+    res = xpx.at(res)[:, :2].set(Z[:, :2] - 1.0)
+    res = xpx.at(res)[:, 2:-1].set(Z[:, 2:])
+
+    def cy_from_mlab_linkage(Zpart, validate):
+        n = Zpart.shape[0]
+        if validate and np.min(Zpart[:, :2]) != 0.0 and np.max(Zpart[:, :2]) != 2 * n:
+            raise ValueError('The format of the indices is not 1..N')
+
+        if not Zpart.flags.writeable:
+            Zpart = Zpart.copy()  # xp=jax.numpy
+
+        CS = np.zeros((n,))
+        _hierarchy.calculate_cluster_sizes(Zpart, CS, n + 1)
+        return CS
+
+    CS = xpx.lazy_apply(cy_from_mlab_linkage, res[:, :-1], validate=lazy,
+                        shape=(res.shape[0],), dtype=xp.float64,
+                        as_numpy=True, xp=xp)
+
+    return xpx.at(res)[:, -1].set(CS)
 
 
 def to_mlab_linkage(Z):
@@ -1938,10 +1964,10 @@ def to_mlab_linkage(Z):
 
     """
     xp = array_namespace(Z)
-    Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
-    if Z.ndim == 0 or (Z.ndim == 1 and Z.shape[0] == 0):
+    Z = _asarray(Z, dtype=xp.float64, xp=xp)
+    if Z.shape in ((), (0, )):
         return xp_copy(Z, xp=xp)
-    _is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
     return xp.concat((Z[:, :2] + 1.0, Z[:, 2:3]), axis=1)
 
@@ -2025,8 +2051,8 @@ def is_monotonic(Z):
 
     """
     xp = array_namespace(Z)
-    Z = _asarray(Z, order='c', xp=xp)
-    _is_valid_linkage(Z, throw=True, name='Z')
+    Z = _asarray(Z, xp=xp)
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
     # We expect the i'th value to be greater than its successor.
     return xp.all(Z[1:, 2] >= Z[:-1, 2])
@@ -2125,16 +2151,17 @@ def is_valid_im(R, warning=False, throw=False, name=None):
     False
 
     """
-    return _is_valid_im(R, warning=warning, throw=throw, name=name, materialize=True)
+    xp = array_namespace(R)
+    R = _asarray(R, xp=xp)
+    return _is_valid_im(R, warning=warning, throw=throw, name=name,
+                        materialize=True, xp=xp)
 
 
-def _is_valid_im(R, warning=False, throw=False, name=None, materialize=False):
+def _is_valid_im(R, warning=False, throw=False, name=None, materialize=False, *, xp):
     """Variant of `is_valid_im` to be called internally by other scipy functions,
     which by default does not materialize lazy input arrays (Dask, JAX, etc.) when
     warning=True or throw=True.
     """
-    xp = array_namespace(R)
-    R = _asarray(R, xp=xp)
     name_str = f"{name!r} " if name else ''
     try:
         if R.dtype != xp.float64:
@@ -2259,17 +2286,18 @@ def is_valid_linkage(Z, warning=False, throw=False, name=None):
     False
 
     """
+    xp = array_namespace(Z)
+    Z = _asarray(Z, xp=xp)
     return _is_valid_linkage(Z, warning=warning, throw=throw,
-                             name=name, materialize=True)
+                             name=name, materialize=True, xp=xp)
 
 
-def _is_valid_linkage(Z, warning=False, throw=False, name=None, materialize=False):
+def _is_valid_linkage(Z, warning=False, throw=False, name=None,
+                      materialize=False, *, xp):
     """Variant of `is_valid_linkage` to be called internally by other scipy functions,
     which by default does not materialize lazy input arrays (Dask, JAX, etc.) when
     warning=True or throw=True.
     """
-    xp = array_namespace(Z)
-    Z = _asarray(Z, xp=xp)
     name_str = f"{name!r} " if name else ''
     try:
         if Z.dtype != xp.float64:
@@ -2397,8 +2425,8 @@ def num_obs_linkage(Z):
 
     """
     xp = array_namespace(Z)
-    Z = _asarray(Z, order='c', xp=xp)
-    _is_valid_linkage(Z, throw=True, name='Z')
+    Z = _asarray(Z, xp=xp)
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
     return Z.shape[0] + 1
 
 
@@ -2451,11 +2479,11 @@ def correspond(Z, Y):
     True
 
     """
-    _is_valid_linkage(Z, throw=True)
-    distance.is_valid_y(Y, throw=True)
     xp = array_namespace(Z, Y)
-    Z = _asarray(Z, order='c', xp=xp)
-    Y = _asarray(Y, order='c', xp=xp)
+    Z = _asarray(Z, xp=xp)
+    Y = _asarray(Y, xp=xp)
+    _is_valid_linkage(Z, throw=True, xp=xp)
+    distance.is_valid_y(Y, throw=True)
     return distance.num_obs_y(Y) == num_obs_linkage(Z)
 
 
@@ -2612,7 +2640,7 @@ def fcluster(Z, t, criterion='inconsistent', depth=2, R=None, monocrit=None):
     """
     xp = array_namespace(Z)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', materialize=True, xp=xp)
 
     n = Z.shape[0] + 1
     T = np.zeros((n,), dtype='i')
@@ -2627,7 +2655,7 @@ def fcluster(Z, t, criterion='inconsistent', depth=2, R=None, monocrit=None):
             R = inconsistent(Z, depth)
         else:
             R = _asarray(R, order='C', dtype=xp.float64, xp=xp)
-            is_valid_im(R, throw=True, name='R')
+            _is_valid_im(R, throw=True, name='R', materialize=True, xp=xp)
             # Since the C code does not support striding using strides.
             # The dimensions are used instead.
             R = np.asarray(R)
@@ -2741,7 +2769,7 @@ def fclusterdata(X, t, criterion='inconsistent',
     if R is None:
         R = inconsistent(Z, d=depth)
     else:
-        R = _asarray(R, order='c', xp=xp)
+        R = _asarray(R, order='C', xp=xp)
     T = fcluster(Z, criterion=criterion, depth=depth, R=R, t=t)
     return T
 
@@ -2796,12 +2824,20 @@ def leaves_list(Z):
     """
     xp = array_namespace(Z)
     Z = _asarray(Z, order='C', xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
+
+    def cy_leaves_list(Z, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+        n = Z.shape[0] + 1
+        ML = np.zeros((n,), dtype=np.int32)
+        _hierarchy.prelist(Z, ML, n)
+        return ML
+
     n = Z.shape[0] + 1
-    ML = np.zeros((n,), dtype='i')
-    Z = np.asarray(Z)
-    _hierarchy.prelist(Z, ML, n)
-    return xp.asarray(ML)
+    return xpx.lazy_apply(cy_leaves_list, Z, validate=is_lazy_array(Z),
+                          shape=(n, ), dtype=xp.int32,
+                          as_numpy=True, xp=xp)
 
 
 # Maps number of leaves to text size.
@@ -3335,7 +3371,7 @@ def llf(id):
     #         None orders leaf nodes based on the order they appear in the
     #         pre-order traversal.
     xp = array_namespace(Z)
-    Z = _asarray(Z, order='c', xp=xp)
+    Z = _asarray(Z, order='C', xp=xp)
 
     if orientation not in ["top", "left", "bottom", "right"]:
         raise ValueError("orientation must be one of 'top', 'left', "
@@ -3349,7 +3385,7 @@ def llf(id):
         if Z.shape[0] + 1 != len_labels:
             raise ValueError("Dimensions of Z and labels must be consistent.")
 
-    is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', materialize=True, xp=xp)
     Zs = Z.shape
     n = Zs[0] + 1
     if isinstance(p, int | float):
@@ -3759,6 +3795,11 @@ def is_isomorphic(T1, T2):
         Whether the flat cluster assignments `T1` and `T2` are
         equivalent.
 
+    Notes
+    -----
+    *Array API support (experimental):* If the input is a lazy Array (e.g. Dask
+    or JAX), the return value will be a 0-dimensional bool Array.
+
     See Also
     --------
     linkage : for a description of what a linkage matrix is.
@@ -3773,7 +3814,7 @@ def is_isomorphic(T1, T2):
     Two flat cluster assignments can be isomorphic if they represent the same
     cluster assignment, with different labels.
 
-    For example, we can use the `scipy.cluster.hierarchy.single`: method
+    For example, we can use the `scipy.cluster.hierarchy.single` method
     and flatten the output to four clusters:
 
     >>> X = [[0, 0], [0, 1], [1, 0],
@@ -3803,34 +3844,37 @@ def is_isomorphic(T1, T2):
     True
 
     """
-    T1 = np.asarray(T1, order='c')
-    T2 = np.asarray(T2, order='c')
+    xp = array_namespace(T1, T2)
+    T1 = _asarray(T1, xp=xp)
+    T2 = _asarray(T2, xp=xp)
 
-    T1S = T1.shape
-    T2S = T2.shape
-
-    if len(T1S) != 1:
+    if T1.ndim != 1:
         raise ValueError('T1 must be one-dimensional.')
-    if len(T2S) != 1:
+    if T2.ndim != 1:
         raise ValueError('T2 must be one-dimensional.')
-    if T1S[0] != T2S[0]:
+    if T1.shape != T2.shape:
         raise ValueError('T1 and T2 must have the same number of elements.')
-    n = T1S[0]
-    d1 = {}
-    d2 = {}
-    for i in range(0, n):
-        if T1[i] in d1:
-            if T2[i] not in d2:
-                return False
-            if d1[T1[i]] != T2[i] or d2[T2[i]] != T1[i]:
+
+    def py_is_isomorphic(T1, T2):
+        d1 = {}
+        d2 = {}
+        for t1, t2 in zip(T1, T2):
+            if t1 in d1:
+                if t2 not in d2:
+                    return False
+                if d1[t1] != t2 or d2[t2] != t1:
+                    return False
+            elif t2 in d2:
                 return False
-        elif T2[i] in d2:
-            return False
-        else:
-            d1[T1[i]] = T2[i]
-            d2[T2[i]] = T1[i]
-    return True
+            else:
+                d1[t1] = t2
+                d2[t2] = t1
+        return True
 
+    res = xpx.lazy_apply(py_is_isomorphic, T1, T2,
+                         shape=(), dtype=xp.bool,
+                         as_numpy=True, xp=xp)
+    return res if is_lazy_array(res) else bool(res)
 
 def maxdists(Z):
     """
@@ -3907,14 +3951,18 @@ def maxdists(Z):
     """
     xp = array_namespace(Z)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
-    n = Z.shape[0] + 1
-    MD = np.zeros((n - 1,))
-    Z = np.asarray(Z)
-    _hierarchy.get_max_dist_for_each_cluster(Z, MD, int(n))
-    MD = xp.asarray(MD)
-    return MD
+    def cy_maxdists(Z, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+        MD = np.zeros((Z.shape[0],))
+        _hierarchy.get_max_dist_for_each_cluster(Z, MD, Z.shape[0] + 1)
+        return MD
+
+    return xpx.lazy_apply(cy_maxdists, Z, validate=is_lazy_array(Z),
+                          shape=(Z.shape[0], ), dtype=xp.float64,
+                          as_numpy=True, xp=xp)
 
 
 def maxinconsts(Z, R):
@@ -3995,19 +4043,25 @@ def maxinconsts(Z, R):
     xp = array_namespace(Z, R)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
     R = _asarray(R, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
-    is_valid_im(R, throw=True, name='R')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
+    _is_valid_im(R, throw=True, name='R', xp=xp)
 
-    n = Z.shape[0] + 1
     if Z.shape[0] != R.shape[0]:
         raise ValueError("The inconsistency matrix and linkage matrix each "
                          "have a different number of rows.")
-    MI = np.zeros((n - 1,))
-    Z = np.asarray(Z)
-    R = np.asarray(R)
-    _hierarchy.get_max_Rfield_for_each_cluster(Z, R, MI, int(n), 3)
-    MI = xp.asarray(MI)
-    return MI
+    
+    def cy_maxinconsts(Z, R, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+            _is_valid_im(R, throw=True, name='R', xp=np)
+        n = Z.shape[0] + 1
+        MI = np.zeros((n - 1,))
+        _hierarchy.get_max_Rfield_for_each_cluster(Z, R, MI, n, 3)
+        return MI
+
+    return xpx.lazy_apply(cy_maxinconsts, Z, R, validate=is_lazy_array(Z),
+                          shape=(Z.shape[0], ), dtype=xp.float64,
+                          as_numpy=True, xp=xp)
 
 
 def maxRstat(Z, R, i):
@@ -4090,8 +4144,8 @@ def maxRstat(Z, R, i):
     xp = array_namespace(Z, R)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
     R = _asarray(R, order='C', dtype=xp.float64, xp=xp)
-    is_valid_linkage(Z, throw=True, name='Z')
-    is_valid_im(R, throw=True, name='R')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
+    _is_valid_im(R, throw=True, name='R', xp=xp)
 
     if not isinstance(i, int):
         raise TypeError('The third argument must be an integer.')
@@ -4103,13 +4157,18 @@ def maxRstat(Z, R, i):
         raise ValueError("The inconsistency matrix and linkage matrix each "
                          "have a different number of rows.")
 
-    n = Z.shape[0] + 1
-    MR = np.zeros((n - 1,))
-    Z = np.asarray(Z)
-    R = np.asarray(R)
-    _hierarchy.get_max_Rfield_for_each_cluster(Z, R, MR, int(n), i)
-    MR = xp.asarray(MR)
-    return MR
+    def cy_maxRstat(Z, R, i, validate):
+        if validate:
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
+            _is_valid_im(R, throw=True, name='R', xp=np)
+        MR = np.zeros((Z.shape[0],))
+        n = Z.shape[0] + 1
+        _hierarchy.get_max_Rfield_for_each_cluster(Z, R, MR, n, i)
+        return MR
+
+    return xpx.lazy_apply(cy_maxRstat, Z, R, i=i, validate=is_lazy_array(Z),
+                          shape=(Z.shape[0], ), dtype=xp.float64,
+                          as_numpy=True, xp=xp)
 
 
 def leaders(Z, T):
@@ -4222,7 +4281,7 @@ def leaders(Z, T):
     xp = array_namespace(Z, T)
     Z = _asarray(Z, order='C', dtype=xp.float64, xp=xp)
     T = _asarray(T, order='C', xp=xp)
-    _is_valid_linkage(Z, throw=True, name='Z')
+    _is_valid_linkage(Z, throw=True, name='Z', xp=xp)
 
     if T.dtype != xp.int32:
         raise TypeError('T must be a 1-D array of dtype int32.')
@@ -4232,9 +4291,9 @@ def leaders(Z, T):
 
     n_obs = Z.shape[0] + 1
 
-    def leaders_(Z, T, validate):
+    def cy_leaders(Z, T, validate):
         if validate:
-            is_valid_linkage(Z, throw=True, name='Z')
+            _is_valid_linkage(Z, throw=True, name='Z', xp=np)
         n_clusters = int(xpx.nunique(T))
         L = np.zeros(n_clusters, dtype=np.int32)
         M = np.zeros(n_clusters, dtype=np.int32)
@@ -4244,6 +4303,6 @@ def leaders_(Z, T, validate):
                              f'when examining linkage node {s} (< 2n-1).')
         return L, M
 
-    return xpx.lazy_apply(leaders_, Z, T, validate=is_lazy_array(Z),
+    return xpx.lazy_apply(cy_leaders, Z, T, validate=is_lazy_array(Z),
                           shape=((None,), (None, )), dtype=(xp.int32, xp.int32),
-                          as_numpy=True)
+                          as_numpy=True, xp=xp)
diff --git a/scipy/cluster/tests/test_hierarchy.py b/scipy/cluster/tests/test_hierarchy.py
index 4e1a620abd52..1eb4c0d8e6ee 100644
--- a/scipy/cluster/tests/test_hierarchy.py
+++ b/scipy/cluster/tests/test_hierarchy.py
@@ -83,11 +83,10 @@ class eager:
 lazy_xp_function(to_tree, jax_jit=False, allow_dask_compute=True,
                  static_argnames=('rd', ))
 lazy_xp_function(optimal_leaf_ordering, static_argnames=('metric',))
-lazy_xp_function(cophenet, jax_jit=False, allow_dask_compute=2)
-lazy_xp_function(inconsistent, jax_jit=False, allow_dask_compute=2,
-                 static_argnames=('d',))
-lazy_xp_function(from_mlab_linkage, jax_jit=False, allow_dask_compute=2)
-lazy_xp_function(to_mlab_linkage, jax_jit=False, allow_dask_compute=1)
+lazy_xp_function(cophenet)
+lazy_xp_function(inconsistent, static_argnames=('d',))
+lazy_xp_function(from_mlab_linkage)
+lazy_xp_function(to_mlab_linkage)
 lazy_xp_function(is_monotonic)
 
 # Note: these functions materialize lazy arrays when warning=True or throw=True
@@ -100,13 +99,12 @@ class eager:
                  static_argnames=('criterion', 'depth'))
 lazy_xp_function(fclusterdata, jax_jit=False, allow_dask_compute=True,
                  static_argnames=('criterion', 'metric', 'depth', 'method'))
-lazy_xp_function(leaves_list, jax_jit=False, allow_dask_compute=2)
+lazy_xp_function(leaves_list)
 lazy_xp_function(dendrogram, jax_jit=False, allow_dask_compute=True)
-lazy_xp_function(is_isomorphic, jax_jit=False, allow_dask_compute=2)
-lazy_xp_function(maxdists, jax_jit=False, allow_dask_compute=True)
-lazy_xp_function(maxinconsts, jax_jit=False, allow_dask_compute=True)
-lazy_xp_function(maxRstat, jax_jit=False, allow_dask_compute=True,
-                 static_argnames=('i',))
+lazy_xp_function(is_isomorphic)
+lazy_xp_function(maxdists)
+lazy_xp_function(maxinconsts)
+lazy_xp_function(maxRstat, static_argnames=('i',))
 
 # Returns data-dependent shape
 lazy_xp_function(leaders, jax_jit=False)
@@ -249,6 +247,7 @@ def test_linkage_cophenet_tdist_Z_Y(self, xp):
         xp_assert_close(c, expectedc, atol=1e-10)
         xp_assert_close(M, expectedM, atol=1e-10)
 
+    @skip_xp_backends("jax.numpy", reason="Can't raise inside jax.pure_callback")
     def test_gh_22183(self, xp):
         # check for lack of segfault
         # (out of bounds memory access)
@@ -377,8 +376,7 @@ def test_leaders_single(self, xp):
         xp_assert_close(xp.concat(L), expect, rtol=1e-15)
 
 
-@skip_xp_backends(np_only=True,
-                  reason='`is_isomorphic` only supports NumPy backend')
+@skip_xp_backends(cpu_only=True, reason='pure-Python algorithm')
 class TestIsIsomorphic:
 
     def test_array_like(self):

```
