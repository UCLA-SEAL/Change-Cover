## [PR 60505](https://github.com/pandas-dev/pandas/pull/60505)

## PR Summary

This PR fixes a bug in the GroupBy method of pandas that ignored the 'group_keys' argument when applied to empty DataFrames or Series. Previously, the output index was incorrectly set to the grouping keys instead of a RangeIndex. The changes include a new test that verifies the correct behavior and ensure that backward compatibility is maintained. This fix enhances the reliability of the GroupBy functionality in pandas and resolves GitHub issue #60471.

## Uncovered Lines

```python
--------------------------------------------------------------------------------
# pandas/core/groupby/generic.py
--------------------------------------------------------------------------------
class NamedAgg(NamedTuple):
...
class SeriesGroupBy(GroupBy[Series]):
    def _wrap_agged_manager(self, mgr: Manager) -> Series:
...
    def _get_data_to_aggregate(
        self, *, numeric_only: bool = False, name: str | None = None
    ) -> SingleBlockManager:
...
    def apply(self, func, *args, **kwargs) -> Series:
...
    def aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs):
...
    def _python_agg_general(self, func, *args, **kwargs):
...
    def _aggregate_multiple_funcs(self, arg, *args, **kwargs) -> DataFrame:
...
    def _wrap_applied_output(
        self,
        data: Series,
        values: list[Any],
        not_indexed_same: bool = False,
        is_transform: bool = False,
    ) -> DataFrame | Series:
...
        Returns
        -------
        DataFrame or Series
        """
        if len(values) == 0:
            # GH #6265
            if is_transform:
                # GH#47787 see test_group_on_empty_multiindex
                res_index = data.index
            elif not self.group_keys:
                res_index = None #â—UNCOVERED: NEED TEST
            else:
                res_index = self._grouper.result_index

            return self.obj._constructor(
                [],
                name=self.obj.name,
                index=res_index,
                dtype=data.dtype,
            )
        assert values is not None
...
    def transform(self, func, *args, engine=None, engine_kwargs=None, **kwargs):
...
    def _cython_transform(self, how: str, numeric_only: bool = False, **kwargs):
...
    def _transform_general(
        self, func: Callable, engine, engine_kwargs, *args, **kwargs
    ) -> Series:
...
    def filter(self, func, dropna: bool = True, *args, **kwargs):
...
        def true_and_notna(x) -> bool:
...
    def nunique(self, dropna: bool = True) -> Series | DataFrame:
...
    def describe(self, percentiles=None, include=None, exclude=None) -> Series:
...
    def value_counts(
        self,
        normalize: bool = False,
        sort: bool = True,
        ascending: bool = False,
        bins=None,
        dropna: bool = True,
    ) -> Series | DataFrame:
...
            def build_codes(lev_codes: np.ndarray) -> np.ndarray:
...
    def take(
        self,
        indices: TakeIndexer,
        **kwargs,
    ) -> Series:
...
    def skew(
        self,
        skipna: bool = True,
        numeric_only: bool = False,
        **kwargs,
    ) -> Series:
...
        def alt(obj):
            # This should not be reached since the cython path should raise
            #  TypeError and not NotImplementedError.
...
    def plot(self) -> GroupByPlot:
...
    def nlargest(
        self, n: int = 5, keep: Literal["first", "last", "all"] = "first"
    ) -> Series:
...
    def nsmallest(
        self, n: int = 5, keep: Literal["first", "last", "all"] = "first"
    ) -> Series:
...
    def idxmin(self, skipna: bool = True) -> Series:
...
    def idxmax(self, skipna: bool = True) -> Series:
...
    def corr(
        self,
        other: Series,
        method: CorrelationMethod = "pearson",
        min_periods: int | None = None,
    ) -> Series:
...
    def cov(
        self, other: Series, min_periods: int | None = None, ddof: int | None = 1
    ) -> Series:
...
    def is_monotonic_increasing(self) -> Series:
...
    def is_monotonic_decreasing(self) -> Series:
...
    def hist(
        self,
        by=None,
        ax=None,
        grid: bool = True,
        xlabelsize: int | None = None,
        xrot: float | None = None,
        ylabelsize: int | None = None,
        yrot: float | None = None,
        figsize: tuple[float, float] | None = None,
        bins: int | Sequence[int] = 10,
        backend: str | None = None,
        legend: bool = False,
        **kwargs,
    ):
...
    def dtype(self) -> Series:
...
    def unique(self) -> Series:
...
class DataFrameGroupBy(GroupBy[DataFrame]):
...
    def aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs):
...
    def _python_agg_general(self, func, *args, **kwargs):
...
    def _aggregate_frame(self, func, *args, **kwargs) -> DataFrame:
...
    def _wrap_applied_output(
        self,
        data: DataFrame,
        values: list,
        not_indexed_same: bool = False,
        is_transform: bool = False,
    ):
...
    def _wrap_applied_output_series(
        self,
        values: list[Series],
        not_indexed_same: bool,
        first_not_none,
        key_index: Index | None,
        is_transform: bool,
    ) -> DataFrame | Series:
...
    def _cython_transform(
        self,
        how: str,
        numeric_only: bool = False,
        **kwargs,
    ) -> DataFrame:
        # We have multi-block tests
        #  e.g. test_rank_min_int, test_cython_transform_frame
        #  test_transform_numeric_ret
...
        def arr_func(bvalues: ArrayLike) -> ArrayLike:
...
    def _transform_general(self, func, engine, engine_kwargs, *args, **kwargs):
...
    def transform(self, func, *args, engine=None, engine_kwargs=None, **kwargs):
...
    def _define_paths(self, func, *args, **kwargs):
...
    def _choose_path(self, fast_path: Callable, slow_path: Callable, group: DataFrame):
...
    def filter(self, func, dropna: bool = True, *args, **kwargs) -> DataFrame:
...
    def __getitem__(self, key) -> DataFrameGroupBy | SeriesGroupBy:
        # per GH 23566
...
    def _gotitem(self, key, ndim: int, subset=None):
...
    def _get_data_to_aggregate(
        self, *, numeric_only: bool = False, name: str | None = None
    ) -> BlockManager:
...
    def _wrap_agged_manager(self, mgr: BlockManager) -> DataFrame:
...
    def _apply_to_column_groupbys(self, func) -> DataFrame:
...
    def nunique(self, dropna: bool = True) -> DataFrame:
...
    def idxmax(
        self,
        skipna: bool = True,
        numeric_only: bool = False,
    ) -> DataFrame:
...
    def idxmin(
        self,
        skipna: bool = True,
        numeric_only: bool = False,
    ) -> DataFrame:
...
    def value_counts(
        self,
        subset: Sequence[Hashable] | None = None,
        normalize: bool = False,
        sort: bool = True,
        ascending: bool = False,
        dropna: bool = True,
    ) -> DataFrame | Series:
...
    def take(
        self,
        indices: TakeIndexer,
        **kwargs,
    ) -> DataFrame:
...
    def skew(
        self,
        skipna: bool = True,
        numeric_only: bool = False,
        **kwargs,
    ) -> DataFrame:
...
        def alt(obj):
            # This should not be reached since the cython path should raise
            #  TypeError and not NotImplementedError.
...
    def plot(self) -> GroupByPlot:
...
    def corr(
        self,
        method: str | Callable[[np.ndarray, np.ndarray], float] = "pearson",
        min_periods: int = 1,
        numeric_only: bool = False,
    ) -> DataFrame:
...
    def cov(
        self,
        min_periods: int | None = None,
        ddof: int | None = 1,
        numeric_only: bool = False,
    ) -> DataFrame:
...
    def hist(
        self,
        column: IndexLabel | None = None,
        by=None,
        grid: bool = True,
        xlabelsize: int | None = None,
        xrot: float | None = None,
        ylabelsize: int | None = None,
        yrot: float | None = None,
        ax=None,
        sharex: bool = False,
        sharey: bool = False,
        figsize: tuple[float, float] | None = None,
        layout: tuple[int, int] | None = None,
        bins: int | Sequence[int] = 10,
        backend: str | None = None,
        legend: bool = False,
        **kwargs,
    ):
...
    def corrwith(
        self,
        other: DataFrame | Series,
        drop: bool = False,
        method: CorrelationMethod = "pearson",
        numeric_only: bool = False,
    ) -> DataFrame:
...
def _wrap_transform_general_frame(
    obj: DataFrame, group: DataFrame, res: DataFrame | Series
) -> DataFrame:

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# pandas/tests/groupby/aggregate/test_aggregate.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# pandas/tests/groupby/test_all_methods.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
# pandas/tests/groupby/test_grouping.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
```

## PR Diff

```diff
diff --git a/doc/source/whatsnew/v3.0.0.rst b/doc/source/whatsnew/v3.0.0.rst
index bb9f48d17b2e1..ab5746eca1b18 100644
--- a/doc/source/whatsnew/v3.0.0.rst
+++ b/doc/source/whatsnew/v3.0.0.rst
@@ -733,6 +733,7 @@ Groupby/resample/rolling
 - Bug in :meth:`.Resampler.interpolate` on a :class:`DataFrame` with non-uniform sampling and/or indices not aligning with the resulting resampled index would result in wrong interpolation (:issue:`21351`)
 - Bug in :meth:`DataFrame.ewm` and :meth:`Series.ewm` when passed ``times`` and aggregation functions other than mean (:issue:`51695`)
 - Bug in :meth:`DataFrameGroupBy.agg` that raises ``AttributeError`` when there is dictionary input and duplicated columns, instead of returning a DataFrame with the aggregation of all duplicate columns. (:issue:`55041`)
+- Bug in :meth:`DataFrameGroupBy.apply` and :meth:`SeriesGroupBy.apply` for empty data frame with ``group_keys=False`` still creating output index using group keys. (:issue:`60471`)
 - Bug in :meth:`DataFrameGroupBy.apply` that was returning a completely empty DataFrame when all return values of ``func`` were ``None`` instead of returning an empty DataFrame with the original columns and dtypes. (:issue:`57775`)
 - Bug in :meth:`DataFrameGroupBy.apply` with ``as_index=False`` that was returning :class:`MultiIndex` instead of returning :class:`Index`. (:issue:`58291`)
 - Bug in :meth:`DataFrameGroupBy.cumsum` and :meth:`DataFrameGroupBy.cumprod` where ``numeric_only`` parameter was passed indirectly through kwargs instead of passing directly. (:issue:`58811`)
diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index 3fa34007a739b..f4e3f3e8b1001 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -583,6 +583,8 @@ def _wrap_applied_output(
             if is_transform:
                 # GH#47787 see test_group_on_empty_multiindex
                 res_index = data.index
+            elif not self.group_keys:
+                res_index = None
             else:
                 res_index = self._grouper.result_index
 
@@ -1967,6 +1969,8 @@ def _wrap_applied_output(
             if is_transform:
                 # GH#47787 see test_group_on_empty_multiindex
                 res_index = data.index
+            elif not self.group_keys:
+                res_index = None
             else:
                 res_index = self._grouper.result_index
 
diff --git a/pandas/tests/groupby/aggregate/test_aggregate.py b/pandas/tests/groupby/aggregate/test_aggregate.py
index 64220f1d3d5b4..b7e6e55739c17 100644
--- a/pandas/tests/groupby/aggregate/test_aggregate.py
+++ b/pandas/tests/groupby/aggregate/test_aggregate.py
@@ -159,6 +159,7 @@ def test_agg_apply_corner(ts, tsframe):
     tm.assert_frame_equal(grouped.agg("sum"), exp_df)
 
     res = grouped.apply(np.sum, axis=0)
+    exp_df = exp_df.reset_index(drop=True)
     tm.assert_frame_equal(res, exp_df)
 
 
diff --git a/pandas/tests/groupby/test_all_methods.py b/pandas/tests/groupby/test_all_methods.py
index 945c3e421a132..4625c5c27a803 100644
--- a/pandas/tests/groupby/test_all_methods.py
+++ b/pandas/tests/groupby/test_all_methods.py
@@ -22,7 +22,7 @@
 def test_multiindex_group_all_columns_when_empty(groupby_func):
     # GH 32464
     df = DataFrame({"a": [], "b": [], "c": []}).set_index(["a", "b", "c"])
-    gb = df.groupby(["a", "b", "c"], group_keys=False)
+    gb = df.groupby(["a", "b", "c"], group_keys=True)
     method = getattr(gb, groupby_func)
     args = get_groupby_method_args(groupby_func, df)
     if groupby_func == "corrwith":
diff --git a/pandas/tests/groupby/test_grouping.py b/pandas/tests/groupby/test_grouping.py
index 366eb59ee226a..4e7c0acb127ed 100644
--- a/pandas/tests/groupby/test_grouping.py
+++ b/pandas/tests/groupby/test_grouping.py
@@ -777,10 +777,21 @@ def test_evaluate_with_empty_groups(self, func, expected):
         # (not testing other agg fns, because they return
         # different index objects.
         df = DataFrame({1: [], 2: []})
-        g = df.groupby(1, group_keys=False)
+        g = df.groupby(1, group_keys=True)
         result = getattr(g[2], func)(lambda x: x)
         tm.assert_series_equal(result, expected)
 
+    def test_groupby_apply_empty_with_group_keys_false(self):
+        # 60471
+        # test apply'ing empty groups with group_keys False
+        # (not testing other agg fns, because they return
+        # different index objects.
+        df = DataFrame({"A": [], "B": [], "C": []})
+        g = df.groupby("A", group_keys=False)
+        result = g.apply(lambda x: x / x.sum(), include_groups=False)
+        expected = DataFrame({"B": [], "C": []}, index=None)
+        tm.assert_frame_equal(result, expected)
+
     def test_groupby_empty(self):
         # https://github.com/pandas-dev/pandas/issues/27190
         s = Series([], name="name", dtype="float64")

```
