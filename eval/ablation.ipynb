{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0501b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:08.610152Z",
     "iopub.status.busy": "2025-07-17T09:17:08.609754Z",
     "iopub.status.idle": "2025-07-17T09:17:08.620836Z",
     "shell.execute_reply": "2025-07-17T09:17:08.620243Z"
    },
    "papermill": {
     "duration": 0.020984,
     "end_time": "2025-07-17T09:17:08.622277",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.601293",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "### Replace these parameters with papermill parameters when running the notebook\n",
    "CONFIG_FILE = \"config/benchmark/scipy_rq.json\"\n",
    "\n",
    "REPO_NAME: str = \"scipy/scipy\"\n",
    "\n",
    "ARTIFACT_FOLDER: str = \"../data/test_augmentation/rq3/scipy\"\n",
    "\n",
    "GENERATOR_NAME_KEY = \"Full ChaCo\"\n",
    "FOLDER_WITH_TESTS = \"chaco_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf443d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:08.635682Z",
     "iopub.status.busy": "2025-07-17T09:17:08.634783Z",
     "iopub.status.idle": "2025-07-17T09:17:08.640280Z",
     "shell.execute_reply": "2025-07-17T09:17:08.639514Z"
    },
    "papermill": {
     "duration": 0.015322,
     "end_time": "2025-07-17T09:17:08.641869",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.626547",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "CONFIG_FILE = \"config/benchmark/scipy_example.json\"\n",
    "REPO_NAME = \"scipy/scipy\"\n",
    "ARTIFACT_FOLDER = \"../data/test_augmentation/rq3/scipy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf11bf",
   "metadata": {
    "papermill": {
     "duration": 0.012446,
     "end_time": "2025-07-17T09:17:08.663598",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.651152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run this via papermill to execute the notebook with the specified parameters.:\n",
    "```bash\n",
    "papermill example_results.ipynb {PROJ}_results.ipynb \\\n",
    "  -p CONFIG_FILE \"config/benchmark/{your PRs}.json\" \\\n",
    "  -p REPO_NAME \"{OWNER}/{PROJ}\" \\\n",
    "  -p ARTIFACT_FOLDER \"../data/test_augmentation/rq3/{PROJ}\" \\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09d25c",
   "metadata": {
    "papermill": {
     "duration": 0.005262,
     "end_time": "2025-07-17T09:17:08.674189",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.668927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plot Coverage Heatmap for a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ce2c9",
   "metadata": {
    "papermill": {
     "duration": 0.004934,
     "end_time": "2025-07-17T09:17:08.684319",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.679385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Load the config file storing the benchmark PRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ae3a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:08.721464Z",
     "iopub.status.busy": "2025-07-17T09:17:08.721092Z",
     "iopub.status.idle": "2025-07-17T09:17:10.230993Z",
     "shell.execute_reply": "2025-07-17T09:17:10.230107Z"
    },
    "papermill": {
     "duration": 1.518779,
     "end_time": "2025-07-17T09:17:10.232476",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.713697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6429f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:08.695805Z",
     "iopub.status.busy": "2025-07-17T09:17:08.695407Z",
     "iopub.status.idle": "2025-07-17T09:17:08.699613Z",
     "shell.execute_reply": "2025-07-17T09:17:08.698850Z"
    },
    "papermill": {
     "duration": 0.016753,
     "end_time": "2025-07-17T09:17:08.706007",
     "exception": false,
     "start_time": "2025-07-17T09:17:08.689254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ChaCo and all ablated variants\n",
    "GENERATORS = {\n",
    "    \"Full ChaCo\": \"chaco_full\",\n",
    "    \"ChaCo (LLM-TC)\": \"llm_tc\",\n",
    "    \"ChaCo (No-TC)\": \"no_tc\",\n",
    "    \"ChaCo (No-Feedback)\": \"no_fb\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566cb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.246602Z",
     "iopub.status.busy": "2025-07-17T09:17:10.246149Z",
     "iopub.status.idle": "2025-07-17T09:17:10.256287Z",
     "shell.execute_reply": "2025-07-17T09:17:10.255486Z"
    },
    "papermill": {
     "duration": 0.019444,
     "end_time": "2025-07-17T09:17:10.258093",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.238649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_GITHUB_TOKEN: str = \"../../../secrets/github_token.txt\"\n",
    "\n",
    "if isinstance(ARTIFACT_FOLDER, str):\n",
    "    ARTIFACT_FOLDER = Path(ARTIFACT_FOLDER)\n",
    "ARTIFACT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Artifacts folder: {ARTIFACT_FOLDER}\")\n",
    "\n",
    "print(\"Repo name:\", REPO_NAME)\n",
    "\n",
    "ARTIFACT_FOLDER_PATH = Path(ARTIFACT_FOLDER)\n",
    "GENERATORS_FOLDERS = {\n",
    "    name: ARTIFACT_FOLDER_PATH / \"test_cases\" / dir_name for name,\n",
    "    dir_name in GENERATORS.items()}\n",
    "\n",
    "GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b4933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.272714Z",
     "iopub.status.busy": "2025-07-17T09:17:10.272515Z",
     "iopub.status.idle": "2025-07-17T09:17:10.276418Z",
     "shell.execute_reply": "2025-07-17T09:17:10.275622Z"
    },
    "papermill": {
     "duration": 0.01302,
     "end_time": "2025-07-17T09:17:10.278071",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.265051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161b9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.292658Z",
     "iopub.status.busy": "2025-07-17T09:17:10.292453Z",
     "iopub.status.idle": "2025-07-17T09:17:10.320914Z",
     "shell.execute_reply": "2025-07-17T09:17:10.320050Z"
    },
    "papermill": {
     "duration": 0.037813,
     "end_time": "2025-07-17T09:17:10.322740",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.284927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the config file to get the list of PRs benchmarked\n",
    "PREFIX = Path(\"../\")\n",
    "\n",
    "with open(PREFIX / CONFIG_FILE, \"r\") as f:\n",
    "    pr_file = json.load(f)\n",
    "    pr_list = pr_file[\"projects\"][REPO_NAME][\"pr_numbers\"]\n",
    "    print(\"Number of PRs used for benchmarking:\", len(pr_list))\n",
    "    print(\"PR list:\", pr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e18df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.338433Z",
     "iopub.status.busy": "2025-07-17T09:17:10.338171Z",
     "iopub.status.idle": "2025-07-17T09:17:10.577842Z",
     "shell.execute_reply": "2025-07-17T09:17:10.576903Z"
    },
    "papermill": {
     "duration": 0.249937,
     "end_time": "2025-07-17T09:17:10.579887",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.329950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_test_data(generators_folders, pr_list, pattern):\n",
    "    \"\"\"\n",
    "    Reads test files, runtime logs, and coverage increments into a nested dictionary.\n",
    "    TEST_DATA[generator][pr_number] = list of test records (dict).\n",
    "\n",
    "    Each test record contains:\n",
    "        - test_name: str\n",
    "        - test_content: str\n",
    "        - runtime_log: str or None\n",
    "        - coverage_increment: dict or None\n",
    "    \"\"\"\n",
    "    test_data = {}\n",
    "\n",
    "    for generator, folder in generators_folders.items():\n",
    "        test_data.setdefault(generator, {})\n",
    "\n",
    "        # For each PR in pr_list, build a path and gather test files\n",
    "        for pr in pr_list:\n",
    "            pr_dir = Path(folder) / str(pr)\n",
    "            if not pr_dir.exists():\n",
    "                print(\n",
    "                    f\"WARNING: {generator}, PR dir {pr_dir} does not exist, skipping...\")\n",
    "                continue\n",
    "\n",
    "            test_data[generator].setdefault(str(pr), [])\n",
    "\n",
    "            # Gather all test_*.py files\n",
    "            test_paths = sorted(pr_dir.glob(\"test_*.py\"))\n",
    "\n",
    "            # Filter out test files not following the pattern\n",
    "            if pattern:\n",
    "                test_paths = [p for p in test_paths\n",
    "                              if re.search(pattern, p.name)]\n",
    "\n",
    "            for test_path in test_paths:\n",
    "                # Skip files that are not regular files\n",
    "                if not test_path.is_file():\n",
    "                    print(\n",
    "                        f\"WARNING: {generator}, PR {pr}, {test_path} is not a file, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                test_name = test_path.stem  # e.g. test_1\n",
    "\n",
    "                with open(test_path, \"r\") as f:\n",
    "                    test_content = f.read()\n",
    "\n",
    "                # The runtime log file is assumed to be test_1_runtime.log, etc.\n",
    "                runtime_log_path = pr_dir / f\"{test_name}_runtime.log\"\n",
    "                if runtime_log_path.exists():\n",
    "                    with open(runtime_log_path, \"r\") as f:\n",
    "                        runtime_log_content = f.read()\n",
    "                else:\n",
    "                    runtime_log_content = None\n",
    "\n",
    "                # Coverage increment json is assumed to be test_1_coverage_increment.json\n",
    "                coverage_inc_path = pr_dir / \\\n",
    "                    f\"{test_name}_coverage_increment.json\"\n",
    "                if coverage_inc_path.exists():\n",
    "                    with open(coverage_inc_path, \"r\") as f:\n",
    "                        coverage_inc_data = json.load(f)\n",
    "                else:\n",
    "                    coverage_inc_data = None\n",
    "\n",
    "                test_data[generator][str(pr)].append({\n",
    "                    \"test_name\": test_name,\n",
    "                    \"test_content\": test_content,\n",
    "                    \"runtime_log\": runtime_log_content,\n",
    "                    \"coverage_increment\": coverage_inc_data\n",
    "                })\n",
    "\n",
    "    return test_data\n",
    "\n",
    "# Build INTEGRATED_TEST_DATA:\n",
    "INTEGRATED_TEST_DATA = load_test_data(GENERATORS_FOLDERS, pr_list,\n",
    "                                      pattern=r\"test_[0-9]+_integrated.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aaba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.602615Z",
     "iopub.status.busy": "2025-07-17T09:17:10.602358Z",
     "iopub.status.idle": "2025-07-17T09:17:10.619095Z",
     "shell.execute_reply": "2025-07-17T09:17:10.618230Z"
    },
    "papermill": {
     "duration": 0.030359,
     "end_time": "2025-07-17T09:17:10.621087",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.590728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_coverage_line(line: str):\n",
    "    \"\"\"\n",
    "    Split a coverage line into its components.\n",
    "    e.g.,\n",
    "    \"scipy/signal/_spline_filters.py:594:c\" -> (\"scipy/signal/_spline_filters.py\", 594)\n",
    "    \"\"\"\n",
    "    line_parts = line.split(\":\")\n",
    "    if len(line_parts) == 3:\n",
    "        return (line_parts[0], int(line_parts[1]))\n",
    "    else:\n",
    "        print(f\"WARNING: Unexpected line format: {line}\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "def aggregate_generators(test_data):\n",
    "    \"\"\"\n",
    "    Aggregates data across ALL PRs for each generator:\n",
    "     - #tests (sum)\n",
    "     - #passed, #failed, #skipped, #errored (sum)\n",
    "     - pass rate (passed / total)\n",
    "     - total unique lines covered (deduplicated across all PRs)\n",
    "     - # PRs with coverage added vs. # all PRs\n",
    "    Prints the results.\n",
    "\n",
    "    Return four dictionaries:\n",
    "        - all_prs\n",
    "        - pass_rates_by_gen_pr\n",
    "        - coverage_added_by_gen_pr\n",
    "        - coverage_added_by_gen_pr_passing_tests\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    all_prs = set()\n",
    "    pass_rates_by_gen_pr = {}\n",
    "    coverage_added_by_gen_pr = {}\n",
    "    coverage_added_by_gen_pr_passing_tests = {}\n",
    "\n",
    "    print(\"\\n=== AGGREGATE STATISTICS ===\")\n",
    "    for generator, pr_dict in test_data.items():\n",
    "        gen_total_tests = 0\n",
    "        gen_passed = 0\n",
    "        gen_failed = 0\n",
    "        gen_skipped = 0\n",
    "        gen_errored = 0\n",
    "\n",
    "        # One set of lines for the entire generator\n",
    "        gen_all_unique_lines = set()\n",
    "        gen_all_unique_lines_passing_tests = set()\n",
    "\n",
    "        # Track how many PRs actually added coverage\n",
    "        coverage_added_pr_count = 0\n",
    "        coverage_added_pr_count_passing_tests = 0\n",
    "        total_prs_for_generator = len(pr_dict)\n",
    "\n",
    "        for pr_number, tests_info in pr_dict.items():\n",
    "\n",
    "            all_prs.add(pr_number)  # Collect all PR numbers\n",
    "\n",
    "            # Collect coverage lines for this PR\n",
    "            pr_covered_lines = set()\n",
    "            pr_covered_lines_passing_tests = set()\n",
    "\n",
    "            #\n",
    "            pr_passed = 0\n",
    "            pr_failed = 0\n",
    "            pr_skipped = 0\n",
    "            pr_errored = 0\n",
    "\n",
    "            for test_record in tests_info:\n",
    "                # Overall test counters\n",
    "                gen_total_tests += 1\n",
    "                passed_flag = False\n",
    "\n",
    "                runtime_log = test_record[\"runtime_log\"] or \"\"\n",
    "                if \"failed\" in runtime_log:\n",
    "                    gen_failed += 1\n",
    "                    pr_failed += 1\n",
    "                elif \"skipped\" in runtime_log:\n",
    "                    gen_skipped += 1\n",
    "                    pr_skipped += 1\n",
    "                elif \"error\" in runtime_log:\n",
    "                    gen_errored += 1\n",
    "                    pr_errored += 1\n",
    "                elif \"passed\" in runtime_log:\n",
    "                    gen_passed += 1\n",
    "                    pr_passed += 1\n",
    "                    passed_flag = True\n",
    "                else:\n",
    "                    # warning\n",
    "                    pass\n",
    "                    # print(f\"WARNING: Unrecognized log for {generator}, PR={pr_number}, test={test_record['test_name']}\")\n",
    "\n",
    "                # Coverage lines\n",
    "                coverage_data = test_record[\"coverage_increment\"]\n",
    "                if coverage_data:\n",
    "\n",
    "                    lines_this_test = coverage_data.get(\n",
    "                        \"unique_lines_covered\", [])\n",
    "                    lines_this_test = [\n",
    "                        (split_coverage_line(line)[0],\n",
    "                         split_coverage_line(line)[1])\n",
    "                        for line in lines_this_test]\n",
    "\n",
    "                    line_missed_by_dev = coverage_data.get(\n",
    "                        \"line_missed_by_dev\", [])\n",
    "                    line_missed_by_dev = [\n",
    "                        (split_coverage_line(line)[0],\n",
    "                         split_coverage_line(line)[1])\n",
    "                        for line in line_missed_by_dev]\n",
    "\n",
    "                    lines_increment = set(lines_this_test) & set(\n",
    "                        line_missed_by_dev)\n",
    "\n",
    "                    # IMPORTANT: filter out coverage of lines that are added in a test file\n",
    "                    # print(lines_this_test)\n",
    "                    lines_increment = [\n",
    "                        (fp, lineno) for fp, lineno in lines_increment\n",
    "                        if not re.search(r\"test\", fp)]\n",
    "\n",
    "                    pr_covered_lines.update(lines_increment)\n",
    "                    if passed_flag:\n",
    "                        pr_covered_lines_passing_tests.update(lines_increment)\n",
    "\n",
    "            # If the PR has any coverage lines, it counts as coverage added\n",
    "            if len(pr_covered_lines) > 0:\n",
    "                coverage_added_pr_count += 1\n",
    "            if len(pr_covered_lines_passing_tests) > 0:\n",
    "                coverage_added_pr_count_passing_tests += 1\n",
    "\n",
    "            # Update the generator-level coverage set\n",
    "            gen_all_unique_lines.update(pr_covered_lines)\n",
    "            gen_all_unique_lines_passing_tests.update(\n",
    "                pr_covered_lines_passing_tests)\n",
    "\n",
    "            # Store the Per PR statistics\n",
    "            pass_rates_by_gen_pr.setdefault(generator, {})[\n",
    "                pr_number] = pr_passed / len(tests_info) * 100 if len(tests_info) else 0.0\n",
    "            coverage_added_by_gen_pr.setdefault(\n",
    "                generator, {})[pr_number] = len(pr_covered_lines)\n",
    "            coverage_added_by_gen_pr_passing_tests.setdefault(\n",
    "                generator, {})[pr_number] = len(\n",
    "                pr_covered_lines_passing_tests)\n",
    "\n",
    "        # Summary for this generator across ALL PRs\n",
    "        generator_pass_rate = (\n",
    "            gen_passed / gen_total_tests) * 100 if gen_total_tests else 0.0\n",
    "        generator_unique_lines_covered = len(gen_all_unique_lines)\n",
    "        generator_unique_lines_passing_tests = len(\n",
    "            gen_all_unique_lines_passing_tests)\n",
    "\n",
    "        print(f\"\\n[Generator={generator}]\")\n",
    "        print(f\"  - Total tests across all PRs: {gen_total_tests}\")\n",
    "        print(\n",
    "            f\"  - Passed: {gen_passed}, Failed: {gen_failed}, Skipped: {gen_skipped}, Errored: {gen_errored}\")\n",
    "        print(f\"  - Pass Rate (overall): {generator_pass_rate:.1f}%\")\n",
    "        print(\n",
    "            f\"  - Total unique lines covered: {generator_unique_lines_covered}\")\n",
    "        print(\n",
    "            f\"  - Total unique lines covered by passing tests: {generator_unique_lines_passing_tests}\")\n",
    "        print(\n",
    "            f\"  - PRs with coverage added / total PRs: {coverage_added_pr_count}/{total_prs_for_generator}\")\n",
    "        print(\n",
    "            f\"  - PRs with coverage added by passing tests / total PRs: {coverage_added_pr_count_passing_tests}/{total_prs_for_generator}\")\n",
    "\n",
    "    # return the dictionaries for further analysis\n",
    "    return all_prs, pass_rates_by_gen_pr, coverage_added_by_gen_pr, coverage_added_by_gen_pr_passing_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85decf85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:10.643835Z",
     "iopub.status.busy": "2025-07-17T09:17:10.643492Z",
     "iopub.status.idle": "2025-07-17T09:17:10.654180Z",
     "shell.execute_reply": "2025-07-17T09:17:10.653531Z"
    },
    "papermill": {
     "duration": 0.024404,
     "end_time": "2025-07-17T09:17:10.656243",
     "exception": false,
     "start_time": "2025-07-17T09:17:10.631839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_coverage_added_by_passing_tests(\n",
    "        coverage_passing_by_gen_pr, all_prs, generators, title_suffix=\"\"):\n",
    "    plt.figure()  # distinct plot\n",
    "    x = np.arange(len(all_prs))\n",
    "    bar_width = 0.8 / len(generators)\n",
    "    for i, gen_name in enumerate(generators):\n",
    "        pr_coverages = [coverage_passing_by_gen_pr[gen_name].get(\n",
    "            pr, 0) for pr in all_prs]\n",
    "        offset = i * bar_width\n",
    "        plt.bar(x + offset, pr_coverages, width=bar_width, label=gen_name)\n",
    "\n",
    "    plt.xticks(x + bar_width*(len(generators)-1)/2, all_prs, rotation=65)\n",
    "    plt.xlabel(\"PR Number\")\n",
    "    plt.ylabel(\"New Lines of Coverage (by passing tests)\")\n",
    "    plt.title(\n",
    "        \"Coverage Added per PR by *Passing* Tests\" +\n",
    "        title_suffix)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195879c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:17:11.918951Z",
     "iopub.status.busy": "2025-07-17T09:17:11.918680Z",
     "iopub.status.idle": "2025-07-17T09:17:13.055972Z",
     "shell.execute_reply": "2025-07-17T09:17:13.054832Z"
    },
    "papermill": {
     "duration": 1.146046,
     "end_time": "2025-07-17T09:17:13.057796",
     "exception": false,
     "start_time": "2025-07-17T09:17:11.911750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_prs, pass_rates_by_gen_pr, coverage_by_gen_pr, coverage_passing_by_gen_pr = \\\n",
    "    aggregate_generators(INTEGRATED_TEST_DATA)\n",
    "\n",
    "##############################################################################\n",
    "# Convert all_prs to a sorted list for consistent plotting\n",
    "all_prs = sorted(all_prs)\n",
    "# Prepare one list of generator names\n",
    "generators = sorted(INTEGRATED_TEST_DATA.keys())\n",
    "\n",
    "\n",
    "plot_coverage_added_by_passing_tests(\n",
    "    coverage_passing_by_gen_pr, all_prs, generators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.694665,
   "end_time": "2025-07-17T09:17:17.445206",
   "environment_variables": {},
   "exception": null,
   "input_path": "compute_pass_rate_cov.ipynb",
   "output_path": "qiskit_results.ipynb",
   "parameters": {
    "ARTIFACT_FOLDER": "../data/test_augmentation/014/qiskit",
    "CONFIG_FILE": "config/benchmark/qiskit_rq.json",
    "FOLDER_WITH_TESTS": "target_gen_base_dynamic_test_context_fb_integrated",
    "GENERATOR_NAME_KEY": "Change and Cover with Dynamic Context",
    "REPO_NAME": "Qiskit/qiskit"
   },
   "start_time": "2025-07-17T09:17:07.750541",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
